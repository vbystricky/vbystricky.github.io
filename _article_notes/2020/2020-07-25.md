---
layout: article_notes
title: Перенос геометрического стиля
date: 2020-07-25
tags: [CV, Object Detection, style transfer]
cite: "arXiv:2007.05471"
link: https://arxiv.org/abs/2007.05471
use_math: true

---

[{{ page.cite }}]({{ page.link }})

Перенос стиля с одной картинки на другую - тема известная, обычно постановка задачи выглядит так: у нас есть две картинки, нам надо взять содержимое
с одной, а "стиль" с другой и сгенерировать третью картинку. Началом этой занимательной истории послужила статья 
[L. A. Gatys et al. "A neural algorithm of artistic style."](https://arxiv.org/abs/1508.06576) в ней честно брались две картинки, и решалась
задача оптимизации, чтобы стиль одной картинки перегнать на другую, очень дорого по ресурсам, кстати. Потом появились всевозможные улучшения и
дополнения. Кому интересно могу порекомендовать обзор, который мне понравился: 
[Haochen Li. "A Literature Review of Neural Style Transfer"](https://www.cs.princeton.edu/courses/archive/spring18/cos598B/public/projects/LiteratureReview/COS598B_spr2018_NeuralStyleTransfer.pdf)
коротенько и по делу. Понятно, что за два года что-то поменялось, но общее представлении вполне можно получить.

Однако, в той статье, что я планирую поразбирать, авторы пишут о неудовлетворительности текущего подхода, который переносит в качестве стиля в
основном текстуры с одного изображения на другое, с большим или меньшим успехом (учитывая, что в последних вариантах, про которые читал, уже
прикручивается семантическая сегментация, для переноса стиля, качество получаемых картинок там очень впечатляет). И предлагают свой вариант,
который кроме текстур перенесет и "геометрический стиль" изображения. 

![Пример переноса обычного и геометрического стилей, картинка из статьи]({{ site.baseurl }}/images/article_notes/2020/arxiv.2007.05471_1.png)

<!--more-->

Прежде чем перейти к разбору, надо ещё ненадолго отвлечься и вспомнить, что же называли "стилем изображения" в базовой статье _L. A. Gatys et al_.
 
Они брали сетку _VGG_, натренированную на ImageNet, и говорили, что раз сетка может классифицировать, значит умеет делать на разных слоях хорошие
отклики (features), и если у двух изображений эти отклики со слоёв VGG сети близкие (в $L^2$ норме), то и содержимое этих изображений близко.
А стилем изображения будем называть матрицу корреляции откликов разных каналов одного слоя сети. Т.е. если у нас есть VGG сеть, мы прогоняем через
нее изображение и на выходе слоя $l$ получаем трёхмерный тензор $F^l_{xyc} \in \mathbb{R}^{W_l \times H_l \times C_l}$, то в качестве стиля мы будем
использовать матрицу Грама:

$$
    G^l_{с s} = \sum_{x,y} F^l_{xyc} \cdot F^l_{xys} 
$$

В том смысле, что если у двух изображений эти матрицы близки, то стили изображений тоже близки.

Переходим к разбираемой статье. Собственно, основное предложение авторов, заключается в том, что перед переносом "текстурного" стиля, надо проделать
геометрическое преобразование картинки, так чтобы она стала геометрически "похожа" на ту с которой берётся стиль. В качестве такого преобразования
авторы предлагают использовать либо аффинное преобразование, либо тонкопленочные сплайны (_thin-plate spline_). Параметры этого преобразования должна
подобрать нейронная сеть. Причём, вообще говоря, совершенно не обязательно копировать и "текстурный" и "геометрический" стиль с одного изображения,
можно с разных. Однако, по порядку.

### Features Extractor

У нас есть две картинки (можно три, если геометрический и текстурный стиль планируем копировать с разных образцов, но для простоты будем считать,
что две). Первая - та у которой мы хотим изменить стиль, и вторая, которая содержит новый стиль. Для выделения откликов (_features_), авторы
предлагают использовать VGG-19, натренированную на ImageNet.

![Feature extraction, картинка из статьи]({{ site.baseurl }}/images/article_notes/2020/arxiv.2007.05471_2.png)

Выделять будем три типа откликов:

1. **Content Features** - это те отклики, которые отвечают за содержимое картинки. И они должны быть близки у исходной фотографии и той, которая
получится в результате переноса стиля. Авторы предлагают использовать отклики с выхода слоя *conv4_2*.

2. **Texture Features** - это отклики отвечающие за "текстурный стиль" изображения, здесь авторы предлагают строить матрицы Грама, аналогично, тому
как это делается в статье _L. A. Gatys et al_, по выходам со слоёв *conv1_1*, *conv2_1*, *conv3_1*, *conv4_1* и *conv5_1*. Матрицы Грама, полученные
таким образом, должны быть близки у результирующей картинки и той, которая служит образцом "текстурного стиля".

3. **Geometric Features** - отклики на базе которых будем строить геометрическое преобразование для изменения исходной картинки. Авторы предлагают
для этих целей брать отклики со слоя *pool_4*.

### Перенос геометрического стиля

Первым переносим геометрический стиль. Этот перенос заключается в геометрическом преобразовании исходного изображения. Авторы предлагают
зафиксировать какой-то тип преобразования (например, аффинное), а его параметры подбирать, используя нейронную сеть. Для этого *geometric features*,
полученные от исходного изображения и изображения содержащего геометрический стиль объединяются в виде тензора корреляции.

$$
    C_{ijkl} = \sum_{c} \hat F_{ijc} \cdot \hat F_{klc}
$$

Крышка над $F$ здесь означает $L^2$ нормализацию вектора откликов. Теперь полученный тензор корреляции отправляется в свёрточную сеть, которая должна
выдать параметры геометрического преобразования:

![Feature extraction, картинка из статьи]({{ site.baseurl }}/images/article_notes/2020/arxiv.2007.05471_3.png)

Чтобы натренировать такую сеть, датасет можно сформировать в автоматическом режиме. Каждый элемент датасета - это тройка: два изображения ($I_a$ и
$I_b$) и параметры геометрического преобразования ($\Theta = \\{\theta_i | i=1,...,p\\}$). Для генерации такой тройки мы берём изображение ($I_a$),
и выбираем случайным образом параметры геометрического преобразования ($\Theta$). Теперь воздействуем этим геометрическим преобразованием на
изображение $I_a$, а потом у получившегося в результате изображения ещё сдвигаем стиль с помощью подхода _L. A. Gatys et al_. Получаем изображение
$I_b$. Таким образом, новый элемент $(I_a, I_b, \Theta)$ датасета готов, повторяя процесс для разных изображений и разных случайных параметров
преобразования - сформируем датасет нужного размера.

В качестве штрафной функции предлагается $L^2$ норма разности изображений $I_b$ и $\mathcal{M}(I_a)$ - результат геометрического преобразования с
параметрами, полученными от сети.

Остаётся отметить, что авторы используют в качестве геометрического преобразования аффинное или _thin-plate spline_, но считают, что и другие
преобразования вполне могут подойти.

### Перенос текстурного стиля

Здесь авторы ничего нового не предлагают. Чтобы перенести текстурный стиль, исходное изображение вначале подвергается геометрическому преобразованию,
затем у того что получилось вычисляются контентные отклики, как было описано ранее. И далее, для получения результирующего изображения, решается
задача оптимизации, а именно, ищется картинка с близкими (в $L^2$ норме) контентными откликами для только что полученных и у которой текстурные
отклики близки к образцу с которого снимаем текстурный стиль. Это, собственно, тоже самое, что проделывается в _L. A. Gatys et al_. Чтобы задачка
лучше сходилась, решают её последовательно на разных масштабах. Вначале для картинок уменьшенных в 8 раз, затем результат увеличивают вдвое и
используют для инициализации следующего уровня и т.д. 

![Пирамида масштабов]({{ site.baseurl }}/images/article_notes/2020/arxiv.2007.05471_4.png)


### Сравнение результатов

На картинке хорошо видно, что отличия от просто переноса текстурного слоя есть, и существенные.

![Сравнение разных подходов, картинка из статьи]({{ site.baseurl }}/images/article_notes/2020/arxiv.2007.05471_5.png)






