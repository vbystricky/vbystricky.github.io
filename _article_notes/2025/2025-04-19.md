---
layout: article_notes
title: Noise-contrastive estimation. A new estimation principle for unnormalized statistical models
date: 2025-04-19
tags: [Statistic]
cite: "AISTATS 2010"
link: https://proceedings.mlr.press/v9/gutmann10a.html
use_math: true
published: true
send2tg: true
---

В статье авторы предлагают метод восстановления параметров распределения по выборке. Особо погружаться интереса нет, хочется пробежаться по верхам
и ознакомится с методикой, потому что ей много где пользуются.

<!--more-->

> Важно отметить, что есть два варианта статьи: [первый от 2010 года](https://proceedings.mlr.press/v9/gutmann10a.html), на который в основном 
> ссылаются в других работах, сильно ужат, поэтому есть смысл читать [второй вариант от 2012](https://www.jmlr.org/papers/volume13/gutmann12a/gutmann12a.pdf)

Допустим, что у нас имеется набор $X = (x_1, ..., x_{T_d})$ данных, полученных из какого-то распределения. Мы знаем, что плотность этого распределения
задаётся функцией вида ${\hat p}_m(.;\alpha)$, но не знаем конкретный вектор параметров $\alpha$.

Причем авторы предлагают не накладывать на плотность обязательное условие нормализованности. Т.е. 

$$
\int {\hat p}_m(u;\alpha) du = с.
$$

и при этом может случиться, что $c \neq 1$ и параметр $c$ надо будет отыскать, вместе с $\alpha$. 

Поэтому обозначим $p_m(u; \theta) = \hat p_m(u;\alpha) / c$ и будем искать вектор параметров $\theta = \\{\alpha; c\\}$.

Основная идея авторов, заключается в том, что искать неизвестное распределение можно, взяв какое-то известное и сравниваясь с ним. Поэтому возьмем
распределение с известной нам плотностью $p_n$ (чуть позже мы уточним, какие $p_n$ подходят, а какие не очень) и сгенерируем еще один набор данных
$Y = (y_1, ..., y_{T_n})$, но уже из $p_n$. 

### Связь с задачей классификации

Сформулируем нашу проблему как задачу классификации.

У нас есть набор данных $U = X \cup Y = (u_1, ..., u_{T_n + T_d})$ для которого мы определим разметку:

$$
C_t = 
\begin{cases}
1, & u_t \in X\\
0, & u_t \in Y
\end{cases},\, t = 1,..., (T_n + T_d)
$$

У нас есть вероятности классов:

$$
P(C = 0) = \frac {T_n} {T_n + T_d}, \; P(C = 1) = \frac {T_d} {T_n + T_d}
$$

Мы знаем как выглядят условные распределения:

$$
p(u | C = 1; \theta) = p_m(u; \theta), \; p(u | C = 0) = p_n(u)
$$

Обозначим: $\nu = P(C = 0) / P(C = 1) = T_n / T_d$ - отношение размеров выборок из вспомогательного и основного распределений, тогда для классов
получим:

$$
P(C = 0| u; \theta) = \frac {\nu p_n(u)} {p_m(u, \theta) + \nu p_n(u)},\;P(C = 1| u; \theta) = \frac {p_m(u, \theta)} {p_m(u, \theta) + \nu p_n(u)}
$$

Обозначим 

$$
G(u,\theta) = \ln \left(\frac {p_m(u, \theta)} {p_n(u)}\right),
$$

тогда

$$
P(C = 0| u; \theta) = \frac {\nu} {\nu + \exp(G(u,\theta))}, \; P(C = 1| u; \theta) = \frac {1} {1 + \nu \exp(-G(u, \theta))}
$$

введем функцию:

$$
h(u; \theta) = S_{\nu}\left(G(u,\theta)\right),
$$

здесь $S_{\nu}(x)$ это сигмоида перекошенная параметром $\nu$:

$$
S_{\nu}(x) = \frac 1 {1 + \nu \exp(-x)}.
$$

Поскольку мы предполагаем, что $C_t$ распределены независимо и соответствуют распределению Бернулли, то логарифмическое правдоподобие даст нам формулу:

$$
{\cal L}(\theta) = \sum_{t=1}^{T_d + T_n} \left(C_t \ln P(C_t = 1| u_t; \theta) + (1 - C_t) \ln P(C_t = 0| u_t; \theta)\right)
$$

или, используя переобозначения, имеем:

$$
{\cal L}(\theta) = \sum_{t=1}^{T_d} \ln h(x_t; \theta) + \sum_{t=1}^{T_т} \ln (1 - h(y_t; \theta))
$$

Оптимизируя функцию ${\cal L}(\theta)$ мы найдем такое $\theta^*$, которое даст нам хорошее представление $G(u, \theta)$ и значит мы восстановим
логарифмическое отношение неизвестного распределения $p_m$ и известного $p_n$.

> $-{\cal L}(\theta)$ это кроссэнтропия, а в целом мы получили "почти" логистическую регрессию

Таким образом авторы показали связь между задачей восстановления параметров неизвестного распределения к задаче бинарной классификации.


### Немного теории и как выбрать вспомогательное распределение

Итак предыдущая часть это была некая интуиция. Чтобы все формализовать, авторы вводят функцию

$$
J_T(\theta) = \frac 1 {T_d} \left( \sum_{t=1}^{T_d} \ln(h(x_t; \theta)) + \sum_{t=1}^{T_n} \ln(1 - h(y_t; \theta))\right)
$$

Это тоже самое, что и ${\cal L}(\theta)$, только нормализованное на размер выборки $T_d$. Можно переписать формулу для $J_T(\theta)$ в виде:

$$
J_T(\theta) = \frac 1 {T_d} \sum_{t=1}^{T_d} \ln(h(x_t; \theta)) + \nu \frac 1 {T_n} \sum_{t=1}^{T_n} \ln(1 - h(y_t; \theta))
$$

По построению у нас $h(u, \theta)$ лежит в пределах от нуля до единицы, логарифмы $\ln(h(x_t; \theta))$ и $\ln(1 - h(y_t; \theta))$, тогда будут
принимать значения в пределах от минус бесконечности до нуля, а значит максимум $J_T(\theta)$ меньше либо равен нулю. Причем равен нулю он только
в том случае, когда для всех $x_t \in X$ имеем $h(x_t, \theta) \rightarrow 1$, а для всех $y_t \in Y$ имеем $h(y_t, \theta) \rightarrow 0$.

При этом:

$$
h(u, \theta) \rightarrow 0,\, \Leftrightarrow G(u,\theta) \rightarrow -\infty,
$$

$$
h(u, \theta) \rightarrow 1,\, \Leftrightarrow G(u,\theta) \rightarrow +\infty
$$

Т.е. мы хотим получить такой параметр $\theta^* $, чтобы $G(x_t, \theta^* )$ был как можно больше для $x_t \in X$ и одновременно $G(y_t, \theta^*)$
был как можно меньше для $y_t \in Y$, а это, возвращаясь к нашей интуиции, как раз и означает, что задача классификации решилась максимально хорошо.

Далее авторы доказывают несколько полезных утверждений относительно $J_T(\theta)$ но мы их пропустим и сразу перейдём к вопросу о том, какими 
свойствами должно обладать вспомогательное распределение, чтобы мы могли попытаться с должной точностью восстановить исходное.

> Желательно, чтобы для исходного распределения мы имели выборку максимально большую - это очевидно и работает всегда.

1. **Вспомогательное распределение надо выбирать таким образом, чтобы $p_n$ имело хорошее аналитическое представление.** Действительно, нам при 
решении задачи оптимизации это $p_n$ надо дифференцировать, поэтому не стоит сильно усложнять себе жизнь, выбирая что-то экзотическое

2. **Выбираем такое распределение $p_n$ из которого можно легко сэмплировать представителей.** Собственно они нам и нужны и было бы странно, если бы
каждый сэмпл приходилось генерировать долго и сложно.

4. **Вспомогательное распределение должно быть "похоже" на то, которое мы хотим восстановить.** В статье доказаны утверждения, которые дают и 
формальные трактовки термина "похоже" и формальные обоснования выбора именно "похожего" на исходное распределение шума. Но и интуитивно понятно, что
чем более близки наши два распределения, тем больше нюансов можно восстановить для искомого, опираясь на шум. Например, крайне желательно, чтобы 
$p_n(u) \neq 0$ там, где $p_m(u; \theta) \neq 0$.

5. **Из вспомогательного распределения надо набирать максимально возможное число примеров.** Т.е. нужно максимально растить $T_n$. Ограничением здесь
будут только вычислительные ресурсы.

