---
layout: article_notes
title: Multi-Dimensional Recurrent Neural Networks
date: 2025-05-02
tags: [RNN]
cite: "arXiv:0705.2011"
link: https://arxiv.org/abs/0705.2011
use_math: true
published: true
send2tg: true
---

[{{ page.cite }}]({{ page.link }})

Мы достаточно подробно обсуждали [рекуррентные нейронные сети]({% link _posts/2021-05-10-rnn_lstm_gru_etc.md %}). Однако, все они рассматривались
применительно к последовательности (одномерной) элементов. Сегодня разберем статью, где предлагается добавить измерений входному набору.  

<!--more-->

Действительно, обычно RNN применяется, когда у нас есть последовательность чего-либо. Это могут быть буквы, слова, аудиозапись. 

> Изображения тоже можно обработь RNN сетью, только надо вначале будет подготовить данные. Например, взять в качестве последовательности набор
> столбцов изображения, или пробежать по изображению (по столбцам потом по строкам или в так называемом Z-order) и получить последовательность
> пикселей

Т.е. обычно мы имеем на входе набор векторов $(I_{1}, I_{2},..., I_{n})$, а RNN превращает их в набор внутренних состояний $(H_{1}, H_{2},..., H_{n})$
и набор выходных векторов $(O_{1}, O_{2},..., O_{n})$. В простейшем случае базовой RNN сети, это выглядит как:

$$
\begin{align*}
H_{t} &= \sigma\left(W^{hi} \cdot I_{t} + W^{hh} \cdot H_{t-1}\right)\\
O_{t} &= W^{oh} \cdot H_{t}
\end{align*}
$$

т.е. на шаге $t$ берем состояние с предыдущего шага $H_{t-1}$ и входной элемент $I_{t}$ из последовательности, проектируем их, складываем и
через нелинейность получаем новое состояние $H_{t}$. Далее проектируем, полученное состояние, и отдаём выходной вектор $O_{t}$.

Можно накручивать в этом месте всякие сложности (так и происходит), получать LSTM, GRU и т.п. вариации исходной сети. Но по факту, мы всегда имеем
входную последовательность, из которой получается последовательность состояний и последовательность откликов.

Авторы статьи задаются вопросом, а нельзя ли обобщить RNN подход на случаи, когда входные данные не одномерны? Ведь, превращая многомерные данные в
одномерную последовательность, чтобы использовать RNN, мы теряем естественную структуру этих данных. 

Рассмотрим в качестве примера цветное изображение $\\{I_{x,y} \in [0, 1]^3| x = 1,...,n; y = 1,...,m\\}$. Развернем его в последовательность пикселей,
проходя последовательно столбцы: $(I_{1,1}, I_{1,2},..., I_{1,m}, I_{2,1}, ..., I_{2,m}, ..., I_{n,1}, ..., I_{n,m})$ и применим обычный RNN. 
Состояние в точке $(x, y)$ вберёт в себя информацию о всех точках $(u, v)$, т.ч. $u < x$ или $u=x,\, v < y$, просто потому что такие точки мы 
обработаем раньше. Однако, степень влияния точки $(x-1, y)$ будет существенно меньше, чем $(x, y-1)$ и даже $(x, y-2)$, потому что её будет отделять 
от $(x, y)$ целый столбец пикселей.

Логично потребовать чтобы ближние точки непосредственно воздействовали на состояние друг друга. Поэтому авторы предлагают MDRNN 
(*multi-dimensional RNN*), изменив исходные формулы следующим образом (мы продолжаем рассматривать двумерное изображение в качестве примера, для
многомерных тензоров не сложно обобщить данный подход):

$$
\begin{align*}
H_{x, y} &= \sigma\left(W^{hi} \cdot I_{x, y} + W^{hh}_x \cdot H_{x-1, y} + W^{hh}_y \cdot H_{x, y - 1}\right)\\
O_{x, y} &= W^{oh} \cdot H_{x, y}
\end{align*}
$$

Важно, что мы при этом двигаемся из левого верхнего угла изображения (точки $(1, 1)$) в правый нижний угол, либо проходя по очереди все столбцы
сверху вниз, либо проходя по очереди все строки слева направо, главное, чтобы в момент, когда мы оказываемся в точке $(x, y)$ состояния $H_{x-1, y}$ и
$H_{x, y-1}$ уже были вычислены.

![MDRNN context]({{ site.baseurl }}/images/article_notes/2025/arxiv.0705.2011_mdrnn_2d_context.svg)

> Для определенности авторы фиксируют, что обходить $D$-мерный тензор мы будем в лексикографическом порядке его координат, т.е. начнем с точки с
> координатами $(1, 1, ..., 1)$ затем $(1, 1, ..., 2)$ и т.д. Таким образом, точку с координатами $(x_1, x_2, ..., x_D)$ мы проходим раньше точки с
> координатами $(y_1, y_2, ..., y_D)$, тогда и только тогда, когда $\exists\,p \in \\{1,..., D\\},\, x_p < y_p$ и $\forall q < p,\, x_q = y_q$.
>
> Для изображения это означает, что мы перебираем столбцы слева направо, проходя каждый сверху вниз.

#### Многомерный bidirectional RNN

В случае одномерных последовательностей, для обычных RNN было обобщение *bidirectional RNN*, когда последовательность одновременно обрабатывалась и в
прямом и в обратном порядках. В каждой точке мы имели два состояния: одно обычное $H_{t}$, собранное от точек до данной, и еще одно $Z_{t}$ от точек
после:

$$
\begin{align*}
H_{t} &= \phi\left(W^{hi} \cdot I_{t} + W^{hh} \cdot H_{t-1}\right)\\
Z_{t} &= \phi\left(W^{zi} \cdot I_{t} + W^{zz} \cdot Z_{t+1}\right)\\
O_{t} &= \sigma\left(W^{oh} \cdot H_{t} + W^{oz} \cdot Z_{t}\right)
\end{align*}
$$

*Bidirectional RNN* так же можно обобщить на многомерный случай, только для $D$-мерного тензора будет $2^D$ начальных точек (углов $D$-мерного куба) и
соответственно столько же слоёв состояний. Авторы отмечают, что $2^D$ небольших слоёв состояний (т.е. когда $H_{t},\,Z_{t}$ и пр. имеют небольшую 
размерность), работают лучше, чем *MDRNN* со слоем $H_{t}$ большей (т.е. больше чем суммарная размерность *BMDRNN*) размерности.

#### Применение

В статье авторы описывают применение своего подхода к сегментационной задаче, и для классификации на MNIST. Статья старая и результаты как таковые не
очень интересны. Интересна сама идея с многомерным RNN.

В продолжение. Есть еще одна статья тех же авторов: *A. Graves and J. Schmidhuber. Offline handwriting recognition with multidimensional recurrent neural networks. 2008,*
[NIPS2008_66368270](https://proceedings.neurips.cc/paper_files/paper/2008/file/66368270ffd51418ec58bd793f2d9b1b-Paper.pdf). В ней более подробные 
формулы для *MDLSTM* и как авторы используют эту модель для распознавания рукописного текста.