---
layout: post
title: Mask R-CNN
date: 2018-07-29
category: Computer vision
tags: [CV, CNN]
use_math: true
---

Разберём статью [1], в которой описана сеть, решающая задачу *сегментации экземпляра объекта* (*object instance segmentation*). Авторы предлагают сеть,
которую они назвали Mask R-CNN. Mask R-CNN берёт за основу [Faster R-CNN]({% post_url 2017-06-14-rcnn_etc %}#faster-r-cnn) и добавляет к ней 
дополнительную ветвь. Эта ветвь на выходе должна выдать маску объекта в дополнение к ограничивающему прямоугольнику и классу.

<!--more-->

Вначале вспомним [Faster R-CNN]({% post_url 2017-06-14-rcnn_etc %}#faster-r-cnn) сеть из [2]. 

![Полная схема Faster R-CNN ]({{ site.baseurl }}/images/2017-06/faster_rcnn.svg)

Она состоит из трёх частей:

1. **Генератор особенностей** (*features extractor*), который, получив на вход изображение, выдаёт 3х-мерный тензор особенностей. При этом каждому 
  вектору особенностей из этого тензора соответствует некоторый прямоугольник исходного изображения. В качестве такого генератора может выступать, 
  например, сеть VGG16 или ResNet101 без полносвязных слоёв.

2. **Region Proposal Network (RPN)**. Сеть, которая получив на вход тензор особенностей, генерирует некоторое количество регионов, в которых 
  предположительно есть объекты

3. **Полносвязные слои** - это сеть, которая для каждого региона, вырезает, соответствующую этому региону, часть из тензора особенностей, и выдаёт 

    3.1. класс объекта (возможно, что класс будет *background*)

    3.2. уточнённый прямоугольник объекта

В статье [1] предлагается добавить дополнительную ветвь к полносвязным слоям, которая генерировала бы бинарную маску внутри прямоугольника объекта. 
Таким образом у сети появляется дополнительный выход размерности $Km^2$, с него для каждого из $K$ классов снимается бинарная маска размера
$m\times m$. Соответственно, схема сети меняется следующим образом:

![Cхема Mask R-CNN ]({{ site.baseurl }}/images/2018-07/mask_rcnn.svg)

> Важно сделать несколько замечаний об отличии Mask R-CNN подхода от случая сегментации изображения. 
> 
> Во-первых, масок выдаётся $K$ штук, т.е. для каждого класса своя маска, поэтому выбор правильной маски мы осуществляем в зависимости от класса, 
> который выдала сеть. Т.е. в данном подходе разделяется предсказание класса и предсказание маски. Это существенное отличие от случая просто
> сегментации изображения, например, описанного в [3], где на выходе мы имеем для каждого пикселя изображения вектор с вероятностями того, что этот
> пиксель принадлежит соответствующему классу. Это отличие определяет и вклад маски в функцию ошибки, если в [3] это *softmax* и затем 
> *мультиноминальная кросс энтропия*, то здесь *сигмоид* и бинарный штраф.
> 
> Во-вторых, сеть генерирует маску фиксированного (не зависящего от размера ROI) размера $m \times m$.

Вернёмся к Mask R-CNN сети.

Большая часть Faster R-CNN схемы сохранена (генератор особенностей, RPN, полносвязные слои для получения класса объекта и уточнения прмоугольника).
Класс и прямоугольник объекта сеть выдаёт в виде векторов небольшой размерности (для класса это вектор вероятностей, для прямоугольника вектор свигов
координат), и их логично генерировать, используя полносвязные слои. Однако, маску, которая по сути бинарное изображение, естественно генерировать, 
сохраняя пространственную структуру, имеющуюся в тензоре особенностей. А значит вместо полносвязных слоёв будем использовать свёрточные. Это в том
числе позволит уменьшить число параметров, а значит упростит тренировку.

### RoIAlign

Еще одно изменение в структуре сети, связанное с желанием получить маску объекта, это замена *RoIPool* слоя на *RoIAlign*. *RoIPool* слой появился в
[Fast R-CNN]({% post_url 2017-06-14-rcnn_etc %}#fast-r-cnn) и был в некотором смысле упрощением подхода [SPPooling]({% post_url 2017-03-08-spp_net %})
из [4]. Для каждого RoI на тензор особенностей накладывалась сетка с фиксированным числом ячеек (например, *7x7*) и к каждой ячейке сетки применялся
MaxPooling, таким образом для каждого прямоугольника претендента получался тензор особенностей, но уже фиксированных пространственных размерностей
(те самые *7x7*). Проблема в том, что при извлечении особенностей для прямоугольника при помощи *RoIPool* процедуры, координаты прямоугольника 
округляются, а ячейки на которые разбит RoI выравниваются по границам особенностей. В случае когда мы хотим только получить класс объекта и его 
расположение на изображении, такой "не точный" подход нас вполне устраивает, поскольку данные характеристики объекта устойчивы к малым сдвигам. Однако,
для получение маски это упрощение не даёт достаточной точности.  

Для наглядности рассмотрим простую ситуацию, когда на RoI накладывается сетка *2x2*:

![Mask R-CNN RoI]({{ site.baseurl }}/images/2018-07/roi.svg)

*RoIPool* после округления координат и выравнивания ячеек по границам особенностей выдаст следующий набор:

![Mask R-CNN RoIPool]({{ site.baseurl }}/images/2018-07/roi_pool.svg)

Авторы статьи [1] предлагают новую процедуру - *RoIAlign*. Не округляя координаты и не выравнивая, в каждой ячейке заводим дополнительную сетку
(в нашем случае обозначаем её зелеными кругами, и берём размеров *2x2*, не путать с ячейками на которые разбит RoI). В каждой точке дополнительной
сетки используем билинейную интерполяцию, чтобы получить значение особенности, а затем используем *MaxPool* для генерации выхода.

![Mask R-CNN RoIAlign]({{ site.baseurl }}/images/2018-07/roi_align.svg)

Утверждается (в [1] есть таблица с результатами тестов), что использование *RoIAlign* слоя улучшает качество работы сети, как относительно случая 
*RoIPool*, так и относительно случая использования подхода, который авторы называют *RoIWarp* (см. [5]). Причем прирост качества относительно *RoIPool*
составляет порядка **7%**.

Со структурой сети разобрались, осталось понять как изменится штрафная функция и процедура тренировки. В случае *Faster R-CNN* штрафная функция
состояла из двух слагаемых:

$$L = L_{cls} + L_{box}$$

первое $L_{cls}$ отвечало за выбор класса объекта, второе $L_{box}$ за ошибку при уточнении координат. Логично добавить еще одно слагаемое $L_{mask}$
для маски. Новая функция ошибки будет:

$$L = L_{cls} + L_{box} + L_{mask}$$

Ошибка $L_{mask}$ считается как усреднение кроссэнтропийной ошибки по сгенерированной маске. При этом, как мы помним, у нас в для каждого объекта 
генерируется $K$ масок по числу возможных классов, но $L_{mask}$ считается только для маски, соответствующей тому классу из которого взят позитив.

### Заключение

Данный подход в рамках решения задачи *instance segmentation* даёт очень хорошие результаты. В качестве примера несколько картинок из статьи [1]:

![Mask R-CNN result]({{ site.baseurl }}/images/2018-07/mask_rcnn_01.png)
![Mask R-CNN result]({{ site.baseurl }}/images/2018-07/mask_rcnn_02.png)
![Mask R-CNN result]({{ site.baseurl }}/images/2018-07/mask_rcnn_03.png)

Ограничения относительно обычной сегментации также понятны, большие протяженные объекты, например, дороги, таким образом искать будет трудновато.

---

### Литература

1. *Kaiming He, Georgia Gkioxari, Piotr Dollar, Ross Girshick, "Mask R-CNN". [arXiv:1409.4842](https://arxiv.org/abs/1703.06870) 2017-2018*

2. *S. Ren, K. He, R. Girshick, and J. Sun, "Faster R-CNN: Towards real-time object detection with region proposal networks," in Neural Information 
Processing Systems (NIPS), 2015.*

3. *E. Shelhamer, J. Long, T. Darrell, "Fully Convolutional Networks for Semantic Segmentation." [arXiv:1605.06211](https://arxiv.org/abs/1605.06211)
2016*

4. *K. He, X. Zhang, S. Ren, J. Sun, "Spatial pyramid pooling in deep convolutional networks for visual recognition." 
[arXiv:1406.4729](https://arxiv.org/abs/1406.4729), 2014*

5. *K. He, J. Dai, J. Sun, "Instance-aware Semantic Segmentation via Multi-task Network Cascades" 
[arXiv:1512.04412](https://arxiv.org/abs/1512.04412), 2015*
